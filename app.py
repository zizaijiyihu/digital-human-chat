"""
æ•°å­—äººå¯¹è¯ç³»ç»Ÿ
æ”¯æŒè§†é¢‘è¾“å…¥ï¼Œè¿”å›éŸ³é¢‘è¾“å‡ºé©±åŠ¨æ•°å­—äºº
"""

import os
import base64
import json
from pathlib import Path
from flask import Flask, request, jsonify, send_from_directory, send_file, Response
from openai import OpenAI
import dashscope
import tempfile
import subprocess
import traceback

app = Flask(__name__, static_folder='static')

# é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
API_KEY = os.getenv('API_KEY')
if not API_KEY:
    raise ValueError('è¯·è®¾ç½®ç¯å¢ƒå˜é‡ API_KEY')

API_BASE = os.getenv('API_BASE', 'https://dashscope.aliyuncs.com/compatible-mode/v1')
MODEL = os.getenv('MODEL', 'qwen3-omni-flash')  # æ”¯æŒéŸ³é¢‘è¾“å‡ºçš„æ¨¡å‹

# éŸ³é¢‘è½¬æ¢æ–¹å¼é…ç½®
# 'wav' - æ·»åŠ  WAV æ–‡ä»¶å¤´ï¼ˆæ¨èï¼Œå»¶è¿Ÿæœ€ä½ï¼‰
# 'mp3' - ä½¿ç”¨ FFmpeg è½¬æ¢ä¸º MP3ï¼ˆå»¶è¿Ÿè¾ƒé«˜ï¼Œå…¼å®¹æ€§å¥½ï¼‰
AUDIO_FORMAT = os.getenv('AUDIO_FORMAT', 'wav')

# OpenAI å®¢æˆ·ç«¯
client = OpenAI(api_key=API_KEY, base_url=API_BASE)

# é…ç½® DashScope SDK
dashscope.api_key = API_KEY
dashscope.base_http_api_url = API_BASE.replace('/compatible-mode/v1', '/api/v1')

# ç¡®ä¿ç›®å½•å­˜åœ¨
Path('test/videos').mkdir(parents=True, exist_ok=True)
Path('test/audios').mkdir(parents=True, exist_ok=True)
Path('static/videos').mkdir(parents=True, exist_ok=True)


# å…¨å±€å˜é‡ï¼šç³»ç»Ÿæç¤ºè¯ï¼ˆä»æ–‡ä»¶åŠ è½½ï¼‰
def load_system_prompt():
    """ä» system_prompt.md æ–‡ä»¶åŠ è½½ç³»ç»Ÿæç¤ºè¯"""
    prompt_file = Path('system_prompt.md')
    if prompt_file.exists():
        with open(prompt_file, 'r', encoding='utf-8') as f:
            content = f.read()
            print(f'âœ… å·²åŠ è½½ç³»ç»Ÿæç¤ºè¯æ–‡ä»¶: {prompt_file} ({len(content)} å­—ç¬¦)')
            return content
    else:
        default_prompt = "ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€ä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¯·ä»”ç»†è§‚çœ‹ç”¨æˆ·çš„è§†é¢‘ï¼Œç†è§£å…¶ä¸­çš„å†…å®¹å’Œé—®é¢˜ï¼Œç”¨æ¸…æ™°ã€è‡ªç„¶çš„è¯­æ°”å›å¤ã€‚"
        print(f'âš ï¸ æœªæ‰¾åˆ° system_prompt.mdï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯')
        return default_prompt

system_prompt = load_system_prompt()

# è§†é¢‘ä¿å­˜è®°å½•
latest_videos = {
    'segments': [],
    'merged': None,
    'timestamp': None
}


def convert_webm_to_mp4(webm_data):
    """å°† WebM è§†é¢‘è½¬æ¢ä¸º MP4 æ ¼å¼"""
    print(f'ğŸ”„ å¼€å§‹è½¬æ¢è§†é¢‘ï¼Œè¾“å…¥å¤§å°: {len(webm_data)} bytes')

    with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as input_file:
        input_file.write(webm_data)
        input_path = input_file.name

    print(f'ğŸ“ ä¸´æ—¶è¾“å…¥æ–‡ä»¶: {input_path}')

    with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as output_file:
        output_path = output_file.name

    print(f'ğŸ“ ä¸´æ—¶è¾“å‡ºæ–‡ä»¶: {output_path}')

    try:
        result = subprocess.run([
            'ffmpeg', '-y', '-i', input_path,
            '-vcodec', 'libx264', '-acodec', 'aac',
            '-preset', 'ultrafast', '-crf', '28',
            output_path
        ], check=True, capture_output=True, text=True)

        print(f'âœ… FFmpeg è½¬æ¢æˆåŠŸ')

        with open(output_path, 'rb') as f:
            mp4_data = f.read()

        print(f'ğŸ“¦ è½¬æ¢å MP4 å¤§å°: {len(mp4_data)} bytes')

        return mp4_data
    except subprocess.CalledProcessError as e:
        print(f'âŒ FFmpeg è½¬æ¢å¤±è´¥ (é€€å‡ºç  {e.returncode}):')
        print(f'=== FFmpeg stdout ===')
        print(e.stdout)
        print(f'=== FFmpeg stderr ===')
        print(e.stderr)
        print(f'=====================')
        raise Exception(f'FFmpeg conversion failed (exit code {e.returncode}): {e.stderr[:200]}')
    finally:
        os.unlink(input_path)
        if os.path.exists(output_path):
            os.unlink(output_path)


def add_wav_header(pcm_data, sample_rate=24000, bits_per_sample=16, channels=1):
    """
    ç»™ PCM æ•°æ®æ·»åŠ  WAV æ–‡ä»¶å¤´

    å‚æ•°:
        pcm_data: åŸå§‹ PCM æ•°æ® (bytes)
        sample_rate: é‡‡æ ·ç‡ (é»˜è®¤ 24000 Hzï¼Œé˜¿é‡Œäº‘é»˜è®¤)
        bits_per_sample: ä½æ·±åº¦ (é»˜è®¤ 16-bit)
        channels: å£°é“æ•° (é»˜è®¤ 1 å•å£°é“)

    è¿”å›:
        å¸¦ WAV æ–‡ä»¶å¤´çš„å®Œæ•´éŸ³é¢‘æ•°æ®
    """
    import struct

    print(f'ğŸ”„ æ·»åŠ  WAV æ–‡ä»¶å¤´ï¼ŒPCM å¤§å°: {len(pcm_data)} bytes')

    # è®¡ç®—å„ç§å‚æ•°
    byte_rate = sample_rate * channels * bits_per_sample // 8
    block_align = channels * bits_per_sample // 8
    data_size = len(pcm_data)
    file_size = data_size + 36  # 44 bytes header - 8 bytes

    # æ„å»º WAV æ–‡ä»¶å¤´ (44 bytes)
    header = struct.pack(
        '<4sI4s4sIHHIIHH4sI',
        b'RIFF',           # ChunkID
        file_size,         # ChunkSize
        b'WAVE',           # Format
        b'fmt ',           # Subchunk1ID
        16,                # Subchunk1Size (16 for PCM)
        1,                 # AudioFormat (1 for PCM)
        channels,          # NumChannels
        sample_rate,       # SampleRate
        byte_rate,         # ByteRate
        block_align,       # BlockAlign
        bits_per_sample,   # BitsPerSample
        b'data',           # Subchunk2ID
        data_size          # Subchunk2Size
    )

    wav_data = header + pcm_data
    print(f'âœ… WAV æ–‡ä»¶å¤´æ·»åŠ å®Œæˆï¼Œæ€»å¤§å°: {len(wav_data)} bytes')

    return wav_data


def convert_pcm_to_mp3(pcm_data):
    """å°† PCM éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º MP3 æ ¼å¼ (ä½¿ç”¨ FFmpeg)"""
    print(f'ğŸ”„ å¼€å§‹è½¬æ¢éŸ³é¢‘ PCM -> MP3ï¼Œè¾“å…¥å¤§å°: {len(pcm_data)} bytes')

    # ä¿å­˜ PCM æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(suffix='.pcm', delete=False) as input_file:
        input_file.write(pcm_data)
        input_path = input_file.name

    with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as output_file:
        output_path = output_file.name

    try:
        # ä½¿ç”¨ ffmpeg å°† PCM è½¬æ¢ä¸º MP3
        # é˜¿é‡Œäº‘è¿”å›çš„åº”è¯¥æ˜¯ 16-bit, 24kHz, mono PCM
        result = subprocess.run([
            'ffmpeg', '-y',
            '-f', 's16le',  # 16-bit signed little-endian
            '-ar', '24000',  # 24kHz sample rate
            '-ac', '1',  # mono
            '-i', input_path,
            '-codec:a', 'libmp3lame',
            '-b:a', '128k',
            output_path
        ], check=True, capture_output=True, text=True)

        print(f'âœ… éŸ³é¢‘è½¬æ¢æˆåŠŸ')

        with open(output_path, 'rb') as f:
            mp3_data = f.read()

        print(f'ğŸ“¦ è½¬æ¢å MP3 å¤§å°: {len(mp3_data)} bytes')

        return mp3_data
    except subprocess.CalledProcessError as e:
        print(f'âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥:')
        print(f'stdout: {e.stdout}')
        print(f'stderr: {e.stderr}')
        raise
    finally:
        os.unlink(input_path)
        if os.path.exists(output_path):
            os.unlink(output_path)


@app.route('/')
def index():
    """ä¸»é¡µ"""
    return send_from_directory('static', 'index.html')


@app.route('/digital-human-component/<path:filename>')
def serve_digital_human(filename):
    """æä¾› digital-human-component é™æ€æ–‡ä»¶"""
    return send_from_directory('digital-human-component', filename)


@app.route('/test/audios/<filename>')
def serve_test_audio(filename):
    """æä¾›æµ‹è¯•éŸ³é¢‘æ–‡ä»¶çš„ HTTP è®¿é—®"""
    return send_from_directory('test/audios', filename)


@app.route('/api/image-commentary-streaming', methods=['POST'])
def image_commentary_streaming():
    """
    å¤„ç†å›¾ç‰‡ç‚¹è¯„ï¼ˆæµå¼è¿”å›ï¼‰
    æ¥æ”¶å›¾ç‰‡ï¼Œå®æ—¶æµå¼è¿”å›éŸ³é¢‘ç‚¹è¯„
    """
    try:
        print('\n' + '='*80)
        print('ğŸ¯ æ”¶åˆ°æµå¼å›¾ç‰‡ç‚¹è¯„è¯·æ±‚')
        print('='*80)

        # è·å–å›¾ç‰‡
        image_file = request.files.get('image')
        if not image_file:
            return jsonify({'error': 'ç¼ºå°‘å›¾ç‰‡æ–‡ä»¶'}), 400

        # è¯»å–å›¾ç‰‡æ•°æ®
        image_data = image_file.read()
        print(f'ğŸ“¦ å›¾ç‰‡å¤§å°: {len(image_data)} bytes')

        # Base64 ç¼–ç å›¾ç‰‡
        image_base64 = base64.b64encode(image_data).decode('utf-8')

        # è·å–å›¾ç‰‡æ ¼å¼ï¼ˆä»æ–‡ä»¶åï¼‰
        filename = image_file.filename.lower()
        if filename.endswith('.jpg') or filename.endswith('.jpeg'):
            image_format = 'jpeg'
        elif filename.endswith('.png'):
            image_format = 'png'
        elif filename.endswith('.gif'):
            image_format = 'gif'
        elif filename.endswith('.webp'):
            image_format = 'webp'
        else:
            # é»˜è®¤ jpeg
            image_format = 'jpeg'

        print(f'ğŸ–¼ï¸ å›¾ç‰‡æ ¼å¼: {image_format}')
        print(f'ğŸ” Base64 ç¼–ç é•¿åº¦: {len(image_base64)} å­—ç¬¦')

        # è°ƒç”¨å¤§æ¨¡å‹ï¼ˆqwen3-omni-flash æ”¯æŒå›¾ç‰‡è¾“å…¥å’ŒéŸ³é¢‘è¾“å‡ºï¼‰
        print(f'â³ è°ƒç”¨å¤§æ¨¡å‹ {MODEL}...')

        # ä½¿ç”¨ data URI æ ¼å¼ï¼ˆä¸å®˜æ–¹ç¤ºä¾‹ç±»ä¼¼ï¼‰
        image_data_uri = f'data:image/{image_format};base64,{image_base64}'

        stream = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    'role': 'user',
                    'content': [
                        {
                            'type': 'image_url',
                            'image_url': {
                                'url': image_data_uri
                            }
                        },
                        {
                            'type': 'text',
                            'text': 'è¯·è¯¦ç»†ç‚¹è¯„è¿™å¼ å›¾ç‰‡ï¼Œæè¿°å›¾ç‰‡çš„å†…å®¹ã€æ„å›¾ã€è‰²å½©ã€æ„å¢ƒç­‰æ–¹é¢ã€‚'
                        }
                    ]
                }
            ],
            modalities=['text', 'audio'],  # è¯·æ±‚éŸ³é¢‘è¾“å‡º
            audio={'voice': 'Cherry', 'format': 'wav'},
            stream=True,
            stream_options={'include_usage': True}
        )

        print('âœ… å¼€å§‹æµå¼è¿”å›éŸ³é¢‘ç‰‡æ®µ')

        def generate():
            """ç”Ÿæˆå™¨å‡½æ•°ï¼Œç´¯ç§¯éŸ³é¢‘åè¿”å›è¾ƒå¤§çš„ç‰‡æ®µ"""
            text_content = ''
            audio_chunk_count = 0
            pcm_buffer = b''  # PCM ç¼“å†²åŒº
            MIN_CHUNK_SIZE = 24000  # æœ€å°å—å¤§å°ï¼š24KB (çº¦ 0.5 ç§’éŸ³é¢‘ @ 24kHz 16-bit mono)
            # æ›´å°çš„å—å¯ä»¥å‡å°‘é˜Ÿåˆ—ç§¯å‹ï¼Œé¿å… "Queue is full" è­¦å‘Š

            for chunk in stream:
                if chunk.choices:
                    delta = chunk.choices[0].delta

                    # æ”¶é›†æ–‡æœ¬ï¼ˆç”¨äºæ—¥å¿—ï¼‰
                    if hasattr(delta, 'content') and delta.content:
                        text_content += delta.content
                        print(f'ğŸ“ æ–‡æœ¬ç‰‡æ®µ: {delta.content}')

                    # ç´¯ç§¯éŸ³é¢‘ç‰‡æ®µ
                    if hasattr(delta, 'audio') and delta.audio:
                        if isinstance(delta.audio, dict) and 'data' in delta.audio:
                            audio_data_chunk = delta.audio['data']

                            # è§£ç  base64 éŸ³é¢‘æ•°æ®å¹¶ç´¯ç§¯åˆ°ç¼“å†²åŒº
                            pcm_chunk = base64.b64decode(audio_data_chunk)
                            pcm_buffer += pcm_chunk
                            print(f'ğŸ”Š ç´¯ç§¯éŸ³é¢‘æ•°æ®: +{len(pcm_chunk)} bytes, æ€»è®¡: {len(pcm_buffer)} bytes')

                            # å½“ç¼“å†²åŒºè¾¾åˆ°æœ€å°å¤§å°æ—¶ï¼Œè¿”å›ä¸€ä¸ªå®Œæ•´çš„ WAV å—
                            if len(pcm_buffer) >= MIN_CHUNK_SIZE:
                                audio_chunk_count += 1
                                wav_chunk = add_wav_header(pcm_buffer)
                                print(f'âœ… è¿”å›éŸ³é¢‘å— #{audio_chunk_count}: {len(wav_chunk)} bytes')
                                yield wav_chunk
                                pcm_buffer = b''  # æ¸…ç©ºç¼“å†²åŒº
                else:
                    # æ‰“å°ä½¿ç”¨ç»Ÿè®¡
                    if hasattr(chunk, 'usage') and chunk.usage:
                        print(f'ğŸ“Š Token ä½¿ç”¨: {chunk.usage}')

            # è¿”å›å‰©ä½™çš„éŸ³é¢‘æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
            if pcm_buffer:
                audio_chunk_count += 1
                wav_chunk = add_wav_header(pcm_buffer)
                print(f'âœ… è¿”å›æœ€åçš„éŸ³é¢‘å— #{audio_chunk_count}: {len(wav_chunk)} bytes')
                yield wav_chunk

            print(f'âœ… æµå¼è¿”å›å®Œæˆ')
            print(f'ğŸ“ å®Œæ•´æ–‡æœ¬: {text_content}')
            print(f'ğŸ”Š æ€»å…±è¿”å› {audio_chunk_count} ä¸ªéŸ³é¢‘å—')

        # è¿”å›æµå¼å“åº”
        return Response(generate(), mimetype='application/octet-stream')

    except Exception as e:
        print(f'âŒ é”™è¯¯: {str(e)}')
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/audio-chat-streaming', methods=['POST'])
def audio_chat_streaming():
    """
    å¤„ç†éŸ³é¢‘å¯¹è¯ï¼ˆæµå¼è¿”å›ï¼‰
    æ¥æ”¶éŸ³é¢‘ï¼Œå®æ—¶æµå¼è¿”å›éŸ³é¢‘ç‰‡æ®µ
    """
    try:
        print('\n' + '='*80)
        print('ğŸ¯ æ”¶åˆ°æµå¼éŸ³é¢‘å¯¹è¯è¯·æ±‚')
        print('='*80)

        # è·å–éŸ³é¢‘
        audio_file = request.files.get('audio')
        if not audio_file:
            return jsonify({'error': 'ç¼ºå°‘éŸ³é¢‘æ–‡ä»¶'}), 400

        # è¯»å–éŸ³é¢‘æ•°æ®ï¼ˆWebM æ ¼å¼ï¼‰
        webm_data = audio_file.read()
        print(f'ğŸ“¦ WebM éŸ³é¢‘å¤§å°: {len(webm_data)} bytes')

        # è½¬æ¢ WebM éŸ³é¢‘ä¸º WAV æ ¼å¼ï¼ˆé˜¿é‡Œäº‘ API æ”¯æŒ WAV æ ¼å¼ï¼‰
        with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as input_file:
            input_file.write(webm_data)
            input_path = input_file.name

        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as output_file:
            output_path = output_file.name

        try:
            print('ğŸ”„ æ­£åœ¨å°† WebM è½¬æ¢ä¸º WAV æ ¼å¼...')
            # è½¬æ¢ä¸º WAV æ ¼å¼
            subprocess.run([
                'ffmpeg', '-y', '-i', input_path,
                '-ar', '24000',  # é‡‡æ ·ç‡ 24kHz (é˜¿é‡Œäº‘æ¨è)
                '-ac', '1',  # å•å£°é“
                '-sample_fmt', 's16',  # 16ä½é‡‡æ ·
                output_path
            ], check=True, capture_output=True, text=True)

            with open(output_path, 'rb') as f:
                wav_data = f.read()

            print(f'ğŸ“¦ è½¬æ¢å WAV å¤§å°: {len(wav_data)} bytes')

            # Base64 ç¼–ç 
            audio_base64 = base64.b64encode(wav_data).decode('utf-8')
            print(f'ğŸ” Base64 ç¼–ç é•¿åº¦: {len(audio_base64)} å­—ç¬¦')

        finally:
            os.unlink(input_path)
            if os.path.exists(output_path):
                os.unlink(output_path)

        # è°ƒç”¨å¤§æ¨¡å‹ï¼ˆqwen3-omni-flash æ”¯æŒéŸ³é¢‘è¾“å…¥å’Œè¾“å‡ºï¼‰
        print(f'â³ è°ƒç”¨å¤§æ¨¡å‹ {MODEL}...')

        # ä½¿ç”¨ data URI æ ¼å¼ï¼ˆä¸è§†é¢‘è¾“å…¥ç›¸åŒçš„æ–¹å¼ï¼‰
        audio_data_uri = f'data:audio/wav;base64,{audio_base64}'
        print(f'ğŸ”— éŸ³é¢‘ Data URI é•¿åº¦: {len(audio_data_uri)} å­—ç¬¦')

        stream = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    'role': 'user',
                    'content': [
                        {
                            'type': 'input_audio',
                            'input_audio': {
                                'data': audio_data_uri,  # ä½¿ç”¨ data URIï¼ˆä¸è§†é¢‘ç›¸åŒï¼‰
                                'format': 'wav'
                            }
                        },
                        {
                            'type': 'text',
                            'text': 'è¯·ç†è§£è¿™æ®µéŸ³é¢‘ä¸­çš„å†…å®¹å’Œé—®é¢˜ï¼Œå¹¶ç”¨è¯­éŸ³å›å¤æˆ‘'
                        }
                    ]
                }
            ],
            modalities=['text', 'audio'],  # è¯·æ±‚éŸ³é¢‘è¾“å‡º
            audio={'voice': 'Cherry', 'format': 'wav'},
            stream=True,
            stream_options={'include_usage': True}
        )

        print('âœ… å¼€å§‹æµå¼è¿”å›éŸ³é¢‘ç‰‡æ®µ')

        def generate():
            """ç”Ÿæˆå™¨å‡½æ•°ï¼Œç´¯ç§¯éŸ³é¢‘åè¿”å›è¾ƒå¤§çš„ç‰‡æ®µ"""
            text_content = ''
            audio_chunk_count = 0
            pcm_buffer = b''  # PCM ç¼“å†²åŒº
            MIN_CHUNK_SIZE = 24000  # æœ€å°å—å¤§å°ï¼š24KB (çº¦ 0.5 ç§’éŸ³é¢‘ @ 24kHz 16-bit mono)
            # æ›´å°çš„å—å¯ä»¥å‡å°‘é˜Ÿåˆ—ç§¯å‹ï¼Œé¿å… "Queue is full" è­¦å‘Š

            for chunk in stream:
                if chunk.choices:
                    delta = chunk.choices[0].delta

                    # æ”¶é›†æ–‡æœ¬ï¼ˆç”¨äºæ—¥å¿—ï¼‰
                    if hasattr(delta, 'content') and delta.content:
                        text_content += delta.content
                        print(f'ğŸ“ æ–‡æœ¬ç‰‡æ®µ: {delta.content}')

                    # ç´¯ç§¯éŸ³é¢‘ç‰‡æ®µ
                    if hasattr(delta, 'audio') and delta.audio:
                        if isinstance(delta.audio, dict) and 'data' in delta.audio:
                            audio_data_chunk = delta.audio['data']

                            # è§£ç  base64 éŸ³é¢‘æ•°æ®å¹¶ç´¯ç§¯åˆ°ç¼“å†²åŒº
                            pcm_chunk = base64.b64decode(audio_data_chunk)
                            pcm_buffer += pcm_chunk
                            print(f'ğŸ”Š ç´¯ç§¯éŸ³é¢‘æ•°æ®: +{len(pcm_chunk)} bytes, æ€»è®¡: {len(pcm_buffer)} bytes')

                            # å½“ç¼“å†²åŒºè¾¾åˆ°æœ€å°å¤§å°æ—¶ï¼Œè¿”å›ä¸€ä¸ªå®Œæ•´çš„ WAV å—
                            if len(pcm_buffer) >= MIN_CHUNK_SIZE:
                                audio_chunk_count += 1
                                wav_chunk = add_wav_header(pcm_buffer)
                                print(f'âœ… è¿”å›éŸ³é¢‘å— #{audio_chunk_count}: {len(wav_chunk)} bytes')
                                yield wav_chunk
                                pcm_buffer = b''  # æ¸…ç©ºç¼“å†²åŒº
                else:
                    # æ‰“å°ä½¿ç”¨ç»Ÿè®¡
                    if hasattr(chunk, 'usage') and chunk.usage:
                        print(f'ğŸ“Š Token ä½¿ç”¨: {chunk.usage}')

            # è¿”å›å‰©ä½™çš„éŸ³é¢‘æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
            if pcm_buffer:
                audio_chunk_count += 1
                wav_chunk = add_wav_header(pcm_buffer)
                print(f'âœ… è¿”å›æœ€åçš„éŸ³é¢‘å— #{audio_chunk_count}: {len(wav_chunk)} bytes')
                yield wav_chunk

            print(f'âœ… æµå¼è¿”å›å®Œæˆ')
            print(f'ğŸ“ å®Œæ•´æ–‡æœ¬: {text_content}')
            print(f'ğŸ”Š æ€»å…±è¿”å› {audio_chunk_count} ä¸ªéŸ³é¢‘å—')

        # è¿”å›æµå¼å“åº”
        return Response(generate(), mimetype='application/octet-stream')

    except Exception as e:
        print(f'âŒ é”™è¯¯: {str(e)}')
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/audio-chat', methods=['POST'])
def audio_chat():
    """
    å¤„ç†éŸ³é¢‘å¯¹è¯ï¼ˆéæµå¼ï¼Œä¿ç•™ç”¨äºå…¼å®¹ï¼‰
    æ¥æ”¶éŸ³é¢‘ï¼Œè¿”å›éŸ³é¢‘
    """
    try:
        print('\n' + '='*80)
        print('ğŸ¯ æ”¶åˆ°éŸ³é¢‘å¯¹è¯è¯·æ±‚')
        print('='*80)

        # è·å–éŸ³é¢‘
        audio_file = request.files.get('audio')
        if not audio_file:
            return jsonify({'error': 'ç¼ºå°‘éŸ³é¢‘æ–‡ä»¶'}), 400

        # è¯»å–éŸ³é¢‘æ•°æ®ï¼ˆWebM æ ¼å¼ï¼‰
        webm_data = audio_file.read()
        print(f'ğŸ“¦ WebM éŸ³é¢‘å¤§å°: {len(webm_data)} bytes')

        # è½¬æ¢ WebM éŸ³é¢‘ä¸º WAV æ ¼å¼ï¼ˆé˜¿é‡Œäº‘ API æ”¯æŒ WAV æ ¼å¼ï¼‰
        with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as input_file:
            input_file.write(webm_data)
            input_path = input_file.name

        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as output_file:
            output_path = output_file.name

        try:
            print('ğŸ”„ æ­£åœ¨å°† WebM è½¬æ¢ä¸º WAV æ ¼å¼...')
            # è½¬æ¢ä¸º WAV æ ¼å¼
            subprocess.run([
                'ffmpeg', '-y', '-i', input_path,
                '-ar', '24000',  # é‡‡æ ·ç‡ 24kHz (é˜¿é‡Œäº‘æ¨è)
                '-ac', '1',  # å•å£°é“
                '-sample_fmt', 's16',  # 16ä½é‡‡æ ·
                output_path
            ], check=True, capture_output=True, text=True)

            with open(output_path, 'rb') as f:
                wav_data = f.read()

            print(f'ğŸ“¦ è½¬æ¢å WAV å¤§å°: {len(wav_data)} bytes')

            # Base64 ç¼–ç 
            audio_base64 = base64.b64encode(wav_data).decode('utf-8')
            print(f'ğŸ” Base64 ç¼–ç é•¿åº¦: {len(audio_base64)} å­—ç¬¦')

        finally:
            os.unlink(input_path)
            if os.path.exists(output_path):
                os.unlink(output_path)

        # è°ƒç”¨å¤§æ¨¡å‹ï¼ˆqwen3-omni-flash æ”¯æŒéŸ³é¢‘è¾“å…¥å’Œè¾“å‡ºï¼‰
        print(f'â³ è°ƒç”¨å¤§æ¨¡å‹ {MODEL}...')

        # ä½¿ç”¨å®˜æ–¹æ–‡æ¡£ä¸­çš„ input_audio ç±»å‹
        stream = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    'role': 'user',
                    'content': [
                        {
                            'type': 'input_audio',
                            'input_audio': {
                                'data': audio_base64,  # ç›´æ¥ä¼  base64 å­—ç¬¦ä¸²
                                'format': 'wav'
                            }
                        },
                        {
                            'type': 'text',
                            'text': 'è¯·ç†è§£è¿™æ®µéŸ³é¢‘ä¸­çš„å†…å®¹å’Œé—®é¢˜ï¼Œå¹¶ç”¨è¯­éŸ³å›å¤æˆ‘'
                        }
                    ]
                }
            ],
            modalities=['text', 'audio'],  # è¯·æ±‚éŸ³é¢‘è¾“å‡º
            audio={'voice': 'Cherry', 'format': 'wav'},
            stream=True,
            stream_options={'include_usage': True}
        )

        print('âœ… å¼€å§‹æ¥æ”¶æµå¼å“åº”')

        # æ”¶é›†æ–‡æœ¬å’ŒéŸ³é¢‘
        text_content = ''
        audio_chunks = []

        for chunk in stream:
            if chunk.choices:
                delta = chunk.choices[0].delta

                # æ”¶é›†æ–‡æœ¬
                if hasattr(delta, 'content') and delta.content:
                    text_content += delta.content
                    print(f'ğŸ“ æ–‡æœ¬ç‰‡æ®µ: {delta.content}')

                # æ”¶é›†éŸ³é¢‘
                if hasattr(delta, 'audio') and delta.audio:
                    if isinstance(delta.audio, dict) and 'data' in delta.audio:
                        audio_data_chunk = delta.audio['data']
                        audio_chunks.append(audio_data_chunk)
                        print(f'ğŸ”Š æ”¶åˆ°éŸ³é¢‘ç‰‡æ®µ: {len(audio_data_chunk)} å­—ç¬¦')
            else:
                # æ‰“å°ä½¿ç”¨ç»Ÿè®¡
                if hasattr(chunk, 'usage') and chunk.usage:
                    print(f'ğŸ“Š Token ä½¿ç”¨: {chunk.usage}')

        print(f'âœ… æµå¼å“åº”æ¥æ”¶å®Œæˆ')
        print(f'ğŸ“ å®Œæ•´æ–‡æœ¬: {text_content}')
        print(f'ğŸ”Š éŸ³é¢‘ç‰‡æ®µæ•°: {len(audio_chunks)}')

        # åˆå¹¶éŸ³é¢‘
        audio_data = None
        audio_format = AUDIO_FORMAT
        if audio_chunks:
            pcm_data = b''.join([base64.b64decode(chunk) for chunk in audio_chunks])
            print(f'ğŸ”Š åˆå¹¶å PCM éŸ³é¢‘å¤§å°: {len(pcm_data)} bytes')

            # æ ¹æ®é…ç½®é€‰æ‹©è½¬æ¢æ–¹å¼
            try:
                if AUDIO_FORMAT == 'mp3':
                    print('ğŸ“ ä½¿ç”¨ MP3 è½¬æ¢æ–¹å¼')
                    audio_data = convert_pcm_to_mp3(pcm_data)
                    file_ext = 'mp3'
                else:
                    print('ğŸ“ ä½¿ç”¨ WAV æ–‡ä»¶å¤´æ–¹å¼')
                    audio_data = add_wav_header(pcm_data)
                    audio_format = 'wav'
                    file_ext = 'wav'

                # ä¿å­˜éŸ³é¢‘åˆ°æµ‹è¯•ç›®å½•
                import time
                audio_path = f'test/audios/audio_response_{int(time.time())}.{file_ext}'
                with open(audio_path, 'wb') as f:
                    f.write(audio_data)
                print(f'ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: {audio_path}')
            except Exception as e:
                print(f'âš ï¸  éŸ³é¢‘è½¬æ¢å¤±è´¥: {e}')
                import traceback
                traceback.print_exc()
                audio_data = None

        # å¦‚æœæ²¡æœ‰éŸ³é¢‘ï¼Œåªè¿”å›æ–‡æœ¬
        if not audio_data:
            print('âš ï¸  æœªæ”¶åˆ°éŸ³é¢‘ï¼Œåªè¿”å›æ–‡æœ¬')
            return jsonify({
                'success': True,
                'text': text_content,
                'hasAudio': False
            })

        # è¿”å›éŸ³é¢‘ï¼ˆbase64ï¼‰
        return jsonify({
            'success': True,
            'text': text_content,
            'hasAudio': True,
            'audio': base64.b64encode(audio_data).decode('utf-8'),
            'audioFormat': audio_format
        })

    except Exception as e:
        print(f'âŒ é”™è¯¯: {str(e)}')
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/video-auto-chat', methods=['POST'])
def video_auto_chat():
    """
    å¤„ç†è§†é¢‘è‡ªåŠ¨é‡‡é›†å¯¹è¯ï¼ˆæµå¼è¿”å›ï¼‰
    æ¥æ”¶å•ä¸ªæˆ–å¤šä¸ªè§†é¢‘ç‰‡æ®µï¼Œè‡ªåŠ¨åˆå¹¶åå‘é€ç»™ AIï¼Œå®æ—¶æµå¼è¿”å›éŸ³é¢‘ç‰‡æ®µ
    """
    try:
        print('\n' + '='*80)
        print('ğŸ¯ æ”¶åˆ°è§†é¢‘è‡ªåŠ¨é‡‡é›†å¯¹è¯è¯·æ±‚')
        print('='*80)

        # è·å–è§†é¢‘æ–‡ä»¶åˆ—è¡¨
        video_files = request.files.getlist('videos')
        if not video_files:
            return jsonify({'error': 'ç¼ºå°‘è§†é¢‘æ–‡ä»¶'}), 400

        print(f'ğŸ“¦ æ”¶åˆ° {len(video_files)} ä¸ªè§†é¢‘ç‰‡æ®µ')

        # å¦‚æœåªæœ‰ä¸€ä¸ªè§†é¢‘ï¼Œè½¬æ¢ä¸º MP4ï¼ˆQwen API ä¸æ”¯æŒ WebMï¼‰
        if len(video_files) == 1:
            print('ğŸ“¹ å•ä¸ªè§†é¢‘ç‰‡æ®µï¼Œè½¬æ¢ä¸º MP4ï¼ˆQwen API è¦æ±‚ï¼‰')
            webm_data = video_files[0].read()
            print(f'ğŸ“¦ WebM å¤§å°: {len(webm_data)} bytes')

            # è½¬æ¢ä¸º MP4
            video_data = convert_webm_to_mp4(webm_data)
            video_mime = 'video/mp4'
            print(f'âœ… MP4 è½¬æ¢æˆåŠŸï¼Œå¤§å°: {len(video_data)} bytes')
        else:
            # å¤šä¸ªè§†é¢‘ï¼Œä½¿ç”¨ ffmpeg åˆå¹¶ä¸º MP4
            print(f'ğŸ”€ å¤šä¸ªè§†é¢‘ç‰‡æ®µï¼Œå¼€å§‹åˆå¹¶ {len(video_files)} ä¸ªç‰‡æ®µ')

            # ä¿å­˜æ‰€æœ‰ WebM æ–‡ä»¶åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_webm_files = []
            temp_mp4_files = []

            for i, video_file in enumerate(video_files):
                webm_data = video_file.read()
                with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as f:
                    f.write(webm_data)
                    temp_webm_files.append(f.name)
                    print(f'  ğŸ“ ç‰‡æ®µ {i+1}: {f.name} ({len(webm_data)} bytes)')

            # å°†æ‰€æœ‰ WebM è½¬æ¢ä¸º MP4ï¼ˆffmpeg åˆå¹¶ MP4 æ›´å¯é ï¼‰
            print('ğŸ”„ ç¬¬ä¸€æ­¥ï¼šå°†æ‰€æœ‰ WebM è½¬æ¢ä¸º MP4...')
            for i, webm_path in enumerate(temp_webm_files):
                mp4_path = webm_path.replace('.webm', '.mp4')
                try:
                    print(f'  ğŸ”„ æ­£åœ¨è½¬æ¢ç‰‡æ®µ {i+1}...')
                    result = subprocess.run([
                        'ffmpeg', '-y', '-i', webm_path,
                        '-vcodec', 'libx264', '-acodec', 'aac',
                        '-preset', 'ultrafast', '-crf', '28',
                        mp4_path
                    ], check=True, capture_output=True, text=True)
                    temp_mp4_files.append(mp4_path)
                    print(f'  âœ… ç‰‡æ®µ {i+1} å·²è½¬æ¢ä¸º MP4')
                except subprocess.CalledProcessError as e:
                    print(f'  âŒ ç‰‡æ®µ {i+1} è½¬æ¢å¤±è´¥ (é€€å‡ºç  {e.returncode}):')
                    print(f'  === FFmpeg stdout (ç‰‡æ®µ {i+1}) ===')
                    print(e.stdout if e.stdout else '(æ— è¾“å‡º)')
                    print(f'  === FFmpeg stderr (ç‰‡æ®µ {i+1}) ===')
                    print(e.stderr if e.stderr else '(æ— è¾“å‡º)')
                    print(f'  ================================')

                    # è·³è¿‡æŸåçš„ç‰‡æ®µï¼Œç»§ç»­å¤„ç†å…¶ä»–ç‰‡æ®µ
                    print(f'  âš ï¸ è·³è¿‡æŸåçš„ç‰‡æ®µ {i+1}ï¼Œç»§ç»­å¤„ç†å…¶ä»–ç‰‡æ®µ...')
                    continue

            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ MP4 æ–‡ä»¶
            if not temp_mp4_files:
                raise Exception('æ‰€æœ‰è§†é¢‘ç‰‡æ®µéƒ½è½¬æ¢å¤±è´¥ï¼Œæ— æ³•ç»§ç»­å¤„ç†')

            # åˆ›å»º ffmpeg concat æ–‡ä»¶åˆ—è¡¨
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as concat_file:
                for mp4_path in temp_mp4_files:
                    concat_file.write(f"file '{mp4_path}'\n")
                concat_file_path = concat_file.name

            print(f'ğŸ“ Concat æ–‡ä»¶: {concat_file_path}')

            # åˆå¹¶æ‰€æœ‰ MP4 æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as output_file:
                output_path = output_file.name

            print('ğŸ”„ ç¬¬äºŒæ­¥ï¼šåˆå¹¶æ‰€æœ‰ MP4 æ–‡ä»¶...')
            subprocess.run([
                'ffmpeg', '-y',
                '-f', 'concat',
                '-safe', '0',
                '-i', concat_file_path,
                '-c', 'copy',  # ç›´æ¥å¤åˆ¶æµï¼Œä¸é‡æ–°ç¼–ç ï¼ˆæ›´å¿«ï¼‰
                output_path
            ], check=True, capture_output=True, text=True)

            print(f'âœ… è§†é¢‘åˆå¹¶å®Œæˆ: {output_path}')

            # è¯»å–åˆå¹¶åçš„ MP4 æ•°æ®
            with open(output_path, 'rb') as f:
                video_data = f.read()
                video_mime = 'video/mp4'

            print(f'ğŸ“¦ åˆå¹¶å MP4 å¤§å°: {len(video_data)} bytes')

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for path in temp_webm_files + temp_mp4_files + [concat_file_path, output_path]:
                try:
                    os.unlink(path)
                except:
                    pass

        # ç¼–ç ä¸º base64
        video_base64 = base64.b64encode(video_data).decode('utf-8')
        print(f'ğŸ” Base64 ç¼–ç é•¿åº¦: {len(video_base64)} å­—ç¬¦')

        # è°ƒç”¨å¤§æ¨¡å‹ï¼ˆæµå¼è¿”å›ï¼‰
        print(f'â³ è°ƒç”¨å¤§æ¨¡å‹ {MODEL}...')
        print(f'ğŸ“Š å¤§æ¨¡å‹è°ƒç”¨å‚æ•°:')
        print(f'   - model: {MODEL}')
        print(f'   - video_format: {video_mime}')
        print(f'   - video_size: {len(video_data)} bytes ({len(video_data) / 1024 / 1024:.2f} MB)')
        print(f'   - base64_length: {len(video_base64)} å­—ç¬¦')
        print(f'   - modalities: [text, audio]')
        print(f'   - audio_voice: Cherry')
        print(f'   - audio_format: wav')
        print(f'   - stream: True')

        stream = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    'role': 'user',
                    'content': [
                        {
                            'type': 'video_url',
                            'video_url': {'url': f'data:{video_mime};base64,{video_base64}'}
                        },
                        {
                            'type': 'text',
                            'text': 'è¯·ç†è§£è¿™æ®µè§†é¢‘ä¸­çš„å†…å®¹å’Œé—®é¢˜ï¼Œå¹¶ç”¨è¯­éŸ³å›å¤æˆ‘ã€‚'
                        }
                    ]
                }
            ],
            modalities=['text', 'audio'],
            audio={'voice': 'Cherry', 'format': 'wav'},
            stream=True,
            stream_options={'include_usage': True}
        )

        print('âœ… å¼€å§‹æµå¼è¿”å›éŸ³é¢‘ç‰‡æ®µ')

        def generate():
            """ç”Ÿæˆå™¨å‡½æ•°ï¼Œç´¯ç§¯éŸ³é¢‘åè¿”å›è¾ƒå¤§çš„ç‰‡æ®µ"""
            text_content = ''
            audio_chunk_count = 0
            pcm_buffer = b''
            MIN_CHUNK_SIZE = 24000  # 24KB (çº¦ 0.5 ç§’éŸ³é¢‘)

            for chunk in stream:
                if chunk.choices:
                    delta = chunk.choices[0].delta

                    # æ”¶é›†æ–‡æœ¬
                    if hasattr(delta, 'content') and delta.content:
                        text_content += delta.content
                        print(f'ğŸ“ æ–‡æœ¬ç‰‡æ®µ: {delta.content}')

                    # ç´¯ç§¯éŸ³é¢‘ç‰‡æ®µ
                    if hasattr(delta, 'audio') and delta.audio:
                        if isinstance(delta.audio, dict) and 'data' in delta.audio:
                            audio_data_chunk = delta.audio['data']

                            # è§£ç  base64 éŸ³é¢‘æ•°æ®å¹¶ç´¯ç§¯åˆ°ç¼“å†²åŒº
                            pcm_chunk = base64.b64decode(audio_data_chunk)
                            pcm_buffer += pcm_chunk
                            print(f'ğŸ”Š ç´¯ç§¯éŸ³é¢‘æ•°æ®: +{len(pcm_chunk)} bytes, æ€»è®¡: {len(pcm_buffer)} bytes')

                            # å½“ç¼“å†²åŒºè¾¾åˆ°æœ€å°å¤§å°æ—¶ï¼Œè¿”å›ä¸€ä¸ªå®Œæ•´çš„ WAV å—
                            if len(pcm_buffer) >= MIN_CHUNK_SIZE:
                                audio_chunk_count += 1
                                wav_chunk = add_wav_header(pcm_buffer)
                                print(f'âœ… è¿”å›éŸ³é¢‘å— #{audio_chunk_count}: {len(wav_chunk)} bytes')
                                yield wav_chunk
                                pcm_buffer = b''
                else:
                    # æ‰“å°ä½¿ç”¨ç»Ÿè®¡
                    if hasattr(chunk, 'usage') and chunk.usage:
                        print(f'ğŸ“Š Token ä½¿ç”¨: {chunk.usage}')

            # è¿”å›å‰©ä½™çš„éŸ³é¢‘æ•°æ®
            if pcm_buffer:
                audio_chunk_count += 1
                wav_chunk = add_wav_header(pcm_buffer)
                print(f'âœ… è¿”å›æœ€åçš„éŸ³é¢‘å— #{audio_chunk_count}: {len(wav_chunk)} bytes')
                yield wav_chunk

            print(f'âœ… æµå¼è¿”å›å®Œæˆ')
            print(f'ğŸ“ å®Œæ•´æ–‡æœ¬: {text_content}')
            print(f'ğŸ”Š æ€»å…±è¿”å› {audio_chunk_count} ä¸ªéŸ³é¢‘å—')

        # è¿”å›æµå¼å“åº”
        return Response(generate(), mimetype='application/octet-stream')

    except Exception as e:
        print(f'âŒ é”™è¯¯: {str(e)}')
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/chat', methods=['POST'])
def chat():
    """
    å¤„ç†è§†é¢‘å¯¹è¯
    æ¥æ”¶è§†é¢‘ï¼Œè¿”å›éŸ³é¢‘
    """
    try:
        print('\n' + '='*80)
        print('ğŸ¯ æ”¶åˆ°å¯¹è¯è¯·æ±‚')
        print('='*80)

        # è·å–è§†é¢‘
        video_file = request.files.get('video')
        if not video_file:
            return jsonify({'error': 'ç¼ºå°‘è§†é¢‘æ–‡ä»¶'}), 400

        # è½¬æ¢è§†é¢‘æ ¼å¼
        webm_data = video_file.read()
        print(f'ğŸ“¦ WebM æ–‡ä»¶å¤§å°: {len(webm_data)} bytes')

        mp4_data = convert_webm_to_mp4(webm_data)
        video_base64 = base64.b64encode(mp4_data).decode('utf-8')
        print(f'ğŸ” Base64 ç¼–ç é•¿åº¦: {len(video_base64)} å­—ç¬¦')

        # è°ƒç”¨å¤§æ¨¡å‹ï¼ˆqwen3-omni-flash æ”¯æŒè§†é¢‘è¾“å…¥å’ŒéŸ³é¢‘è¾“å‡ºï¼‰
        # é‡è¦ï¼šstream å¿…é¡»ä¸º True æ‰èƒ½è¿”å›éŸ³é¢‘ï¼
        print(f'â³ è°ƒç”¨å¤§æ¨¡å‹ {MODEL}...')
        stream = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    'role': 'user',
                    'content': [
                        {
                            'type': 'video_url',
                            'video_url': {'url': f'data:video/mp4;base64,{video_base64}'}
                        },
                        {
                            'type': 'text',
                            'text': 'è¯·ç†è§£è¿™æ®µè§†é¢‘ä¸­çš„å†…å®¹å’Œé—®é¢˜ï¼Œå¹¶ç”¨è¯­éŸ³å›å¤æˆ‘ã€‚'
                        }
                    ]
                }
            ],
            modalities=['text', 'audio'],  # è¯·æ±‚éŸ³é¢‘è¾“å‡º
            audio={'voice': 'Cherry', 'format': 'wav'},  # ä½¿ç”¨é˜¿é‡Œäº‘æ”¯æŒçš„å£°éŸ³
            stream=True,  # å¿…é¡»ä¸º Trueï¼
            stream_options={'include_usage': True}
        )

        print('âœ… å¼€å§‹æ¥æ”¶æµå¼å“åº”')

        # æ”¶é›†æ–‡æœ¬å’ŒéŸ³é¢‘
        text_content = ''
        audio_chunks = []

        for chunk in stream:
            if chunk.choices:
                delta = chunk.choices[0].delta

                # æ”¶é›†æ–‡æœ¬
                if hasattr(delta, 'content') and delta.content:
                    text_content += delta.content
                    print(f'ğŸ“ æ–‡æœ¬ç‰‡æ®µ: {delta.content}')

                # æ”¶é›†éŸ³é¢‘ï¼ˆæ³¨æ„ï¼šaudio æ˜¯å­—å…¸ï¼Œä¸æ˜¯å¯¹è±¡ï¼‰
                if hasattr(delta, 'audio') and delta.audio:
                    # delta.audio æ˜¯å­—å…¸: {'data': 'base64_string'}
                    if isinstance(delta.audio, dict) and 'data' in delta.audio:
                        audio_data_chunk = delta.audio['data']
                        audio_chunks.append(audio_data_chunk)
                        print(f'ğŸ”Š æ”¶åˆ°éŸ³é¢‘ç‰‡æ®µ: {len(audio_data_chunk)} å­—ç¬¦')
            else:
                # æ‰“å°ä½¿ç”¨ç»Ÿè®¡
                if hasattr(chunk, 'usage') and chunk.usage:
                    print(f'ğŸ“Š Token ä½¿ç”¨: {chunk.usage}')

        print(f'âœ… æµå¼å“åº”æ¥æ”¶å®Œæˆ')
        print(f'ğŸ“ å®Œæ•´æ–‡æœ¬: {text_content}')
        print(f'ğŸ”Š éŸ³é¢‘ç‰‡æ®µæ•°: {len(audio_chunks)}')

        # åˆå¹¶éŸ³é¢‘
        audio_data = None
        audio_format = AUDIO_FORMAT
        if audio_chunks:
            # éŸ³é¢‘æ˜¯ base64 ç¼–ç çš„ï¼Œéœ€è¦è§£ç 
            pcm_data = b''.join([base64.b64decode(chunk) for chunk in audio_chunks])
            print(f'ğŸ”Š åˆå¹¶å PCM éŸ³é¢‘å¤§å°: {len(pcm_data)} bytes')

            # æ ¹æ®é…ç½®é€‰æ‹©è½¬æ¢æ–¹å¼
            try:
                if AUDIO_FORMAT == 'mp3':
                    # æ–¹å¼1: ä½¿ç”¨ FFmpeg è½¬æ¢ä¸º MP3ï¼ˆå»¶è¿Ÿè¾ƒé«˜ï¼‰
                    print('ğŸ“ ä½¿ç”¨ MP3 è½¬æ¢æ–¹å¼')
                    audio_data = convert_pcm_to_mp3(pcm_data)
                    file_ext = 'mp3'
                else:
                    # æ–¹å¼2: æ·»åŠ  WAV æ–‡ä»¶å¤´ï¼ˆæ¨èï¼Œå»¶è¿Ÿæœ€ä½ï¼‰
                    print('ğŸ“ ä½¿ç”¨ WAV æ–‡ä»¶å¤´æ–¹å¼')
                    audio_data = add_wav_header(pcm_data)
                    audio_format = 'wav'
                    file_ext = 'wav'

                # ä¿å­˜éŸ³é¢‘åˆ°æµ‹è¯•ç›®å½•
                import time
                audio_path = f'test/audios/response_{int(time.time())}.{file_ext}'
                with open(audio_path, 'wb') as f:
                    f.write(audio_data)
                print(f'ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: {audio_path}')
            except Exception as e:
                print(f'âš ï¸  éŸ³é¢‘è½¬æ¢å¤±è´¥: {e}')
                import traceback
                traceback.print_exc()
                audio_data = None

        # å¦‚æœæ²¡æœ‰éŸ³é¢‘ï¼Œåªè¿”å›æ–‡æœ¬
        if not audio_data:
            print('âš ï¸  æœªæ”¶åˆ°éŸ³é¢‘ï¼Œåªè¿”å›æ–‡æœ¬')
            return jsonify({
                'success': True,
                'text': text_content,
                'hasAudio': False
            })

        # è¿”å›éŸ³é¢‘ï¼ˆbase64ï¼‰
        return jsonify({
            'success': True,
            'text': text_content,
            'hasAudio': True,
            'audio': base64.b64encode(audio_data).decode('utf-8'),
            'audioFormat': audio_format
        })

    except Exception as e:
        print(f'âŒ é”™è¯¯: {str(e)}')
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/video-auto-chat-with-tts', methods=['POST'])
def video_auto_chat_with_tts():
    """
    è§†é¢‘ç†è§£ + æµå¼ TTS åˆæˆ
    åˆ†ç¦»å¼æ¶æ„ï¼šè§†é¢‘ç†è§£ï¼ˆçº¯æ–‡æœ¬ï¼‰+ Qwen3-TTS æµå¼åˆæˆ
    """
    try:
        print('\n' + '='*80)
        print('ğŸ¯ æ”¶åˆ°è§†é¢‘ç†è§£ + æµå¼ TTS è¯·æ±‚')
        print('='*80)

        # 1. è·å–å¹¶åˆå¹¶è§†é¢‘ç‰‡æ®µï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼‰
        video_files = request.files.getlist('videos')
        if not video_files:
            return jsonify({'error': 'ç¼ºå°‘è§†é¢‘æ–‡ä»¶'}), 400

        print(f'ğŸ“¦ æ”¶åˆ° {len(video_files)} ä¸ªè§†é¢‘ç‰‡æ®µ')

        # åˆå¹¶è§†é¢‘ï¼ˆä¸ç°æœ‰ video_auto_chat ç›¸åŒçš„é€»è¾‘ï¼‰
        if len(video_files) == 1:
            print('ğŸ“¹ å•ä¸ªè§†é¢‘ç‰‡æ®µï¼Œè½¬æ¢ä¸º MP4')
            webm_data = video_files[0].read()
            video_data = convert_webm_to_mp4(webm_data)
            video_mime = 'video/mp4'
        else:
            print(f'ğŸ”€ å¤šä¸ªè§†é¢‘ç‰‡æ®µï¼Œå¼€å§‹åˆå¹¶ {len(video_files)} ä¸ªç‰‡æ®µ')
            temp_webm_files = []
            temp_mp4_files = []

            for i, video_file in enumerate(video_files):
                webm_data = video_file.read()
                with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as f:
                    f.write(webm_data)
                    temp_webm_files.append(f.name)

            # è½¬æ¢æ‰€æœ‰ WebM ä¸º MP4
            for i, webm_path in enumerate(temp_webm_files):
                mp4_path = webm_path.replace('.webm', '.mp4')
                try:
                    subprocess.run([
                        'ffmpeg', '-y', '-i', webm_path,
                        '-vcodec', 'libx264', '-acodec', 'aac',
                        '-preset', 'ultrafast', '-crf', '28',
                        mp4_path
                    ], check=True, capture_output=True, text=True)
                    temp_mp4_files.append(mp4_path)
                except subprocess.CalledProcessError:
                    print(f'  âš ï¸ è·³è¿‡æŸåçš„ç‰‡æ®µ {i+1}')
                    continue

            if not temp_mp4_files:
                raise Exception('æ‰€æœ‰è§†é¢‘ç‰‡æ®µéƒ½è½¬æ¢å¤±è´¥')

            # åˆ›å»º concat æ–‡ä»¶å¹¶åˆå¹¶
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as concat_file:
                for mp4_path in temp_mp4_files:
                    concat_file.write(f"file '{mp4_path}'\n")
                concat_file_path = concat_file.name

            with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as output_file:
                output_path = output_file.name

            subprocess.run([
                'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
                '-i', concat_file_path, '-c', 'copy', output_path
            ], check=True, capture_output=True, text=True)

            with open(output_path, 'rb') as f:
                video_data = f.read()
                video_mime = 'video/mp4'

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for path in temp_webm_files + temp_mp4_files + [concat_file_path, output_path]:
                try:
                    os.unlink(path)
                except:
                    pass

        # 2. è§†é¢‘ç†è§£ï¼ˆåªè·å–æ–‡æœ¬ï¼‰
        video_base64 = base64.b64encode(video_data).decode('utf-8')

        print('\n' + '='*80)
        print('ğŸ“¤ å‘é€ç»™å¤§æ¨¡å‹çš„å®Œæ•´è¯·æ±‚ï¼ˆè§†é¢‘ç†è§£ï¼‰')
        print('='*80)
        print(f'ğŸ¤– Model: {MODEL}')
        print(f'ğŸ“Š Modalities: [text]')
        print(f'ğŸ“¹ Video: {video_mime}, {len(video_data)} bytes ({len(video_data) / 1024 / 1024:.2f} MB)')
        print(f'\nğŸ“ Messages:')
        print(f'  [1] Role: system')
        print(f'      Content (å‰200å­—ç¬¦):')
        print(f'      {system_prompt[:200]}...')
        print(f'      (æ€»é•¿åº¦: {len(system_prompt)} å­—ç¬¦)')
        print(f'  [2] Role: user')
        print(f'      Content: [video] data:{video_mime};base64,...(base64 {len(video_base64)} å­—ç¬¦)')
        print('='*80 + '\n')

        print('â³ æ­¥éª¤ 1: è°ƒç”¨ Qwen3-Omni-Flash è¿›è¡Œè§†é¢‘ç†è§£ï¼ˆçº¯æ–‡æœ¬æ¨¡å¼ï¼‰...')

        # æ³¨æ„ï¼šè™½ç„¶æˆ‘ä»¬å¯ä»¥ç”¨ stream=Trueï¼Œä½†å› ä¸ºéœ€è¦è§£æå®Œæ•´ JSON æ‰èƒ½æå– message å’Œ actionsï¼Œ
        # æ‰€ä»¥å®é™…ä¸Šè¿˜æ˜¯éœ€è¦ç­‰å¾…å®Œæ•´å“åº”ã€‚ä½¿ç”¨ stream=False æ›´ç®€å•ç›´æ¥ã€‚
        understanding_response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {'role': 'system', 'content': system_prompt},
                {
                    'role': 'user',
                    'content': [
                        {
                            'type': 'video_url',
                            'video_url': {'url': f'data:{video_mime};base64,{video_base64}'}
                        }
                    ]
                }
            ],
            modalities=['text'],  # åªè¦æ–‡æœ¬ï¼
            stream=False  # éœ€è¦å®Œæ•´ JSON æ‰èƒ½è§£æ message å’Œ actions
        )

        text_response = understanding_response.choices[0].message.content
        print(f'ğŸ“ AI æ–‡æœ¬å“åº” (å‰200å­—ç¬¦): {text_response[:200]}...')
        print(f'ğŸ“ å®Œæ•´å“åº”é•¿åº¦: {len(text_response)} å­—ç¬¦')
        print(f'â±ï¸  è§†é¢‘ç†è§£å®Œæˆï¼Œç«‹å³å¼€å§‹ TTS æµå¼åˆæˆ...')

        # å°è¯•è§£æ JSONï¼ˆå¦‚æœ system_prompt è¦æ±‚è¿”å› JSONï¼‰
        tts_text = text_response
        actions = []
        try:
            response_json = json.loads(text_response)
            if 'message' in response_json:
                tts_text = response_json.get('message', text_response)
            if 'actions' in response_json:
                actions = response_json.get('actions', [])
                print(f'ğŸ“‹ è§£æåˆ°çš„ actions: {actions}')
        except json.JSONDecodeError:
            print('ğŸ“ å“åº”ä¸æ˜¯ JSON æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨æ–‡æœ¬')

        # 3. æµå¼ TTS åˆæˆ
        print(f'\nâ³ æ­¥éª¤ 2: è°ƒç”¨ Qwen3-TTS-Flash è¿›è¡Œæµå¼éŸ³é¢‘åˆæˆ...')
        print(f'ğŸµ TTS æ–‡æœ¬ (å‰100å­—ç¬¦): {tts_text[:100]}...')

        def generate_audio_stream():
            """æµå¼ç”ŸæˆéŸ³é¢‘å¹¶è¿”å› WAV æ•°æ®ï¼ˆç´¯ç§¯åæ·»åŠ  WAV headerï¼‰"""
            try:
                # âœ… ç¬¬ä¸€æ­¥ï¼šå…ˆå‘é€ JSON å…ƒæ•°æ®å—ï¼ˆåŒ…å« actions å’Œ messageï¼‰
                metadata = {
                    'type': 'metadata',
                    'message': tts_text,
                    'actions': actions
                }
                metadata_json = json.dumps(metadata, ensure_ascii=False)
                metadata_bytes = metadata_json.encode('utf-8')

                # å‘é€å…ƒæ•°æ®é•¿åº¦ï¼ˆ4å­—èŠ‚ï¼‰+ å…ƒæ•°æ®å†…å®¹
                metadata_length = len(metadata_bytes)
                yield metadata_length.to_bytes(4, byteorder='big')  # é•¿åº¦å‰ç¼€
                yield metadata_bytes  # JSON æ•°æ®

                print(f'ğŸ“‹ å·²å‘é€å…ƒæ•°æ®å—: {len(actions)} ä¸ª actions, æ¶ˆæ¯é•¿åº¦ {len(tts_text)} å­—ç¬¦')

                # âœ… ç¬¬äºŒæ­¥ï¼šè°ƒç”¨ Qwen3-TTS æµå¼ API ç”ŸæˆéŸ³é¢‘
                # æ³¨æ„ï¼šQwen3-TTS ä½¿ç”¨ text å‚æ•°ï¼Œä¸æ˜¯ messages
                responses = dashscope.MultiModalConversation.call(
                    model="qwen3-tts-flash",
                    text=tts_text,  # âœ… ç›´æ¥ä¼  text å‚æ•°ï¼
                    voice="Cherry",
                    language_type="Chinese",
                    stream=True
                )

                chunk_count = 0
                pcm_buffer = b''
                MIN_CHUNK_SIZE = 24000  # 24KB (çº¦ 0.5 ç§’éŸ³é¢‘ï¼Œä¸æ—§æ¥å£ä¸€è‡´)

                for response in responses:
                    if response.status_code == 200:
                        audio = response.output.get('audio', {})
                        if audio and audio.data:
                            # DashScope è¿”å› base64 ç¼–ç çš„ PCM æ•°æ®
                            pcm_chunk = base64.b64decode(audio.data)
                            pcm_buffer += pcm_chunk
                            print(f'  ğŸ”Š TTS ç´¯ç§¯éŸ³é¢‘: +{len(pcm_chunk)} bytes, æ€»è®¡: {len(pcm_buffer)} bytes')

                            # å½“ç¼“å†²åŒºè¾¾åˆ°æœ€å°å¤§å°æ—¶ï¼Œè¿”å›ä¸€ä¸ªå®Œæ•´çš„ WAV å—
                            if len(pcm_buffer) >= MIN_CHUNK_SIZE:
                                chunk_count += 1
                                wav_chunk = add_wav_header(pcm_buffer, sample_rate=24000)
                                print(f'  âœ… è¿”å› TTS éŸ³é¢‘å— #{chunk_count}: {len(wav_chunk)} bytes')
                                yield wav_chunk
                                pcm_buffer = b''

                        if response.output.get('finish_reason') == 'stop':
                            print(f'âœ… TTS æµå¼ç”Ÿæˆå®Œæˆ')
                            break
                    else:
                        print(f'âŒ TTS é”™è¯¯: {response.message}')
                        break

                # è¿”å›å‰©ä½™çš„éŸ³é¢‘æ•°æ®
                if pcm_buffer:
                    chunk_count += 1
                    wav_chunk = add_wav_header(pcm_buffer, sample_rate=24000)
                    print(f'  âœ… è¿”å›æœ€åçš„ TTS éŸ³é¢‘å— #{chunk_count}: {len(wav_chunk)} bytes')
                    yield wav_chunk

                print(f'ğŸµ TTS æ€»å…±è¿”å› {chunk_count} ä¸ª WAV éŸ³é¢‘å—')

            except Exception as e:
                print(f'âŒ TTS ç”Ÿæˆå¤±è´¥: {e}')
                traceback.print_exc()

        # è¿”å›æµå¼æ•°æ®ï¼šå…ˆå‘é€å…ƒæ•°æ®å—ï¼Œå†å‘é€éŸ³é¢‘æµ
        return Response(
            generate_audio_stream(),
            mimetype='application/octet-stream',
            headers={
                'Content-Type': 'application/octet-stream',
                'Cache-Control': 'no-cache'
            }
        )

    except Exception as e:
        print(f'âŒ å¤„ç†å¤±è´¥: {e}')
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/system-prompt', methods=['GET'])
def get_system_prompt():
    """è·å–å½“å‰çš„ç³»ç»Ÿæç¤ºè¯"""
    global system_prompt
    return jsonify({'prompt': system_prompt})


@app.route('/api/system-prompt', methods=['POST'])
def update_system_prompt():
    """æ›´æ–°ç³»ç»Ÿæç¤ºè¯"""
    global system_prompt
    try:
        data = request.get_json()
        if not data or 'prompt' not in data:
            return jsonify({'error': 'ç¼ºå°‘ prompt å‚æ•°'}), 400

        new_prompt = data['prompt'].strip()
        if not new_prompt:
            return jsonify({'error': 'æç¤ºè¯ä¸èƒ½ä¸ºç©º'}), 400

        system_prompt = new_prompt
        print(f'âœ… ç³»ç»Ÿæç¤ºè¯å·²æ›´æ–° (é•¿åº¦: {len(system_prompt)} å­—ç¬¦)')

        return jsonify({'success': True, 'prompt': system_prompt})
    except Exception as e:
        print(f'âŒ æ›´æ–°ç³»ç»Ÿæç¤ºè¯å¤±è´¥: {e}')
        return jsonify({'error': str(e)}), 500


@app.route('/api/latest-videos', methods=['GET'])
def get_latest_videos():
    """è·å–æœ€æ–°ä¿å­˜çš„è§†é¢‘æ–‡ä»¶ä¿¡æ¯"""
    global latest_videos

    if not latest_videos['segments'] and not latest_videos['merged']:
        return jsonify({'error': 'æš‚æ— è§†é¢‘', 'segments': [], 'merged': None})

    result = {
        'segments': [
            {
                'filename': segment['filename'],
                'url': f'/static/videos/{segment["filename"]}',
                'type': segment['type'],
                'original_name': segment['original_name']
            }
            for segment in latest_videos['segments']
        ],
        'merged': {
            'filename': latest_videos['merged'],
            'url': f'/static/videos/{latest_videos["merged"]}'
        } if latest_videos['merged'] else None,
        'timestamp': latest_videos['timestamp']
    }

    return jsonify(result)


if __name__ == '__main__':
    print('ğŸš€ æ•°å­—äººå¯¹è¯ç³»ç»Ÿå¯åŠ¨ï¼')
    print(f'ğŸ“¡ è®¿é—®åœ°å€: http://localhost:5001')
    print(f'ğŸ¤– ä½¿ç”¨æ¨¡å‹: {MODEL}')
    print(f'ğŸµ éŸ³é¢‘æ ¼å¼: {AUDIO_FORMAT.upper()} {"(å¿«é€Ÿ)" if AUDIO_FORMAT == "wav" else "(å…¼å®¹)"}')
    print(f'ğŸ’¬ ç³»ç»Ÿæç¤ºè¯: å·²åŠ è½½ ({len(system_prompt)} å­—ç¬¦)')

    app.run(host='0.0.0.0', port=5001, debug=True)
